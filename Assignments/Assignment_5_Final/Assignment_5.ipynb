{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnet.model import Sequential\n",
    "from nnet.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Flatten,\n",
    ")\n",
    "from nnet.utils import one_hot\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "X_train = loadmat(os.path.join(DATA_DIR, \"train_images.mat\"))[\"train_images\"]\n",
    "X_test = loadmat(os.path.join(DATA_DIR, \"test_images.mat\"))[\"test_images\"]\n",
    "y_train = loadmat(os.path.join(DATA_DIR, \"train_labels.mat\"))[\"train_labels\"]\n",
    "y_test = loadmat(os.path.join(DATA_DIR, \"test_labels.mat\"))[\"test_labels\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28, 1, 1000), (28, 28, 1, 1000))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the data compatible with the model\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "X_train = X_train[:, :, np.newaxis, :]\n",
    "X_test = X_test[:, :, np.newaxis, :]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "X_train = X_train / X_train.max() - 0.5\n",
    "X_test = X_test / X_test.max() - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 1000), (10, 1000))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding the labels\n",
    "y_train = np.squeeze(y_train.T)\n",
    "y_test = np.squeeze(y_test.T)\n",
    "y_train = one_hot(y_train, 10)\n",
    "y_test = one_hot(y_test, 10)\n",
    "\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** I'm using the updated version of the module which I created for the previous assignment. To see how to work with the module, please refer to the previous assignment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: CNN Model\n",
      "_________________________________________________________________________________________________\n",
      "╒═════════╤════════════════╤═════════════════╤═════════════════╤═══════════════╤════════════════╕\n",
      "│ Name    │ Input Shapes   │ Output Shapes   │ Weight Shapes   │ Bias Shapes   │   # Parameters │\n",
      "╞═════════╪════════════════╪═════════════════╪═════════════════╪═══════════════╪════════════════╡\n",
      "│ Input   │ (28, 28, 1)    │ (28, 28, 1)     │ None            │ None          │              0 │\n",
      "├─────────┼────────────────┼─────────────────┼─────────────────┼───────────────┼────────────────┤\n",
      "│ Conv    │ (28, 28, 1)    │ (13, 13, 9)     │ (3, 3, 1, 9)    │ (9, 1)        │             90 │\n",
      "├─────────┼────────────────┼─────────────────┼─────────────────┼───────────────┼────────────────┤\n",
      "│ MaxPool │ (13, 13, 9)    │ (6, 6, 9)       │ None            │ None          │              0 │\n",
      "├─────────┼────────────────┼─────────────────┼─────────────────┼───────────────┼────────────────┤\n",
      "│ Flatten │ (6, 6, 9)      │ (324,)          │ None            │ None          │              0 │\n",
      "├─────────┼────────────────┼─────────────────┼─────────────────┼───────────────┼────────────────┤\n",
      "│ Output  │ (324,)         │ (10,)           │ (10, 324)       │ (10, 1)       │           3250 │\n",
      "╘═════════╧════════════════╧═════════════════╧═════════════════╧═══════════════╧════════════════╛\n",
      "=================================================================================================\n",
      "Total Parameters: 3340\n",
      "_________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\"CNN Model\")\n",
    "inp = Input((28, 28, 1), name=\"Input\")\n",
    "conv = Conv2D(9, (3, 3), padding=\"valid\", activation=\"relu\", name=\"Conv\")\n",
    "pool = MaxPool2D((2, 2), 2, name=\"MaxPool\")\n",
    "flat = Flatten(name=\"Flatten\")\n",
    "dense = Dense(10, name=\"Output\", activation=\"softmax\")\n",
    "\n",
    "model.add(inp)\n",
    "model.add(conv)\n",
    "model.add(pool)\n",
    "model.add(flat)\n",
    "model.add(dense)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the model has just 3340 parameters. Would this be enough to learn the data? Let's find out. For this, we compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_cross_entropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    initializer=\"glorot\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001/0050 | Loss: 2.56050 | Accuracy: 0.18200 | \n",
      "Epoch 0002/0050 | Loss: 2.44336 | Accuracy: 0.20800 | \n",
      "Epoch 0003/0050 | Loss: 2.35812 | Accuracy: 0.21400 | \n",
      "Epoch 0004/0050 | Loss: 2.29177 | Accuracy: 0.21200 | \n",
      "Epoch 0005/0050 | Loss: 2.23784 | Accuracy: 0.21100 | \n",
      "Epoch 0006/0050 | Loss: 2.19254 | Accuracy: 0.21200 | \n",
      "Epoch 0007/0050 | Loss: 2.15412 | Accuracy: 0.30300 | \n",
      "Epoch 0008/0050 | Loss: 2.12118 | Accuracy: 0.30900 | \n",
      "Epoch 0009/0050 | Loss: 2.09269 | Accuracy: 0.31700 | \n",
      "Epoch 0010/0050 | Loss: 2.06748 | Accuracy: 0.32400 | \n",
      "Epoch 0011/0050 | Loss: 2.04555 | Accuracy: 0.32700 | \n",
      "Epoch 0012/0050 | Loss: 2.02632 | Accuracy: 0.32900 | \n",
      "Epoch 0013/0050 | Loss: 2.00957 | Accuracy: 0.33200 | \n",
      "Epoch 0014/0050 | Loss: 1.99492 | Accuracy: 0.33000 | \n",
      "Epoch 0015/0050 | Loss: 1.98208 | Accuracy: 0.32900 | \n",
      "Epoch 0016/0050 | Loss: 1.97072 | Accuracy: 0.33200 | \n",
      "Epoch 0017/0050 | Loss: 1.96073 | Accuracy: 0.33300 | \n",
      "Epoch 0018/0050 | Loss: 1.95208 | Accuracy: 0.33000 | \n",
      "Epoch 0019/0050 | Loss: 1.94455 | Accuracy: 0.33000 | \n",
      "Epoch 0020/0050 | Loss: 1.93779 | Accuracy: 0.32900 | \n",
      "Epoch 0021/0050 | Loss: 1.93199 | Accuracy: 0.33200 | \n",
      "Epoch 0022/0050 | Loss: 1.92699 | Accuracy: 0.33500 | \n",
      "Epoch 0023/0050 | Loss: 1.92250 | Accuracy: 0.33300 | \n",
      "Epoch 0024/0050 | Loss: 1.91830 | Accuracy: 0.33600 | \n",
      "Epoch 0025/0050 | Loss: 1.91448 | Accuracy: 0.33700 | \n",
      "Epoch 0026/0050 | Loss: 1.91109 | Accuracy: 0.33600 | \n",
      "Epoch 0027/0050 | Loss: 1.90838 | Accuracy: 0.33900 | \n",
      "Epoch 0028/0050 | Loss: 1.90624 | Accuracy: 0.34300 | \n",
      "Epoch 0029/0050 | Loss: 1.90439 | Accuracy: 0.34700 | \n",
      "Epoch 0030/0050 | Loss: 1.90300 | Accuracy: 0.34900 | \n",
      "Epoch 0031/0050 | Loss: 1.90178 | Accuracy: 0.35000 | \n",
      "Epoch 0032/0050 | Loss: 1.90051 | Accuracy: 0.34900 | \n",
      "Epoch 0033/0050 | Loss: 1.89907 | Accuracy: 0.35000 | \n",
      "Epoch 0034/0050 | Loss: 1.89647 | Accuracy: 0.34700 | \n",
      "Epoch 0035/0050 | Loss: 1.89163 | Accuracy: 0.34800 | \n",
      "Epoch 0036/0050 | Loss: 1.88653 | Accuracy: 0.35200 | \n",
      "Epoch 0037/0050 | Loss: 1.88185 | Accuracy: 0.35200 | \n",
      "Epoch 0038/0050 | Loss: 1.87717 | Accuracy: 0.35400 | \n",
      "Epoch 0039/0050 | Loss: 1.87196 | Accuracy: 0.35500 | \n",
      "Epoch 0040/0050 | Loss: 1.86731 | Accuracy: 0.35600 | \n",
      "Epoch 0041/0050 | Loss: 1.86298 | Accuracy: 0.35800 | \n",
      "Epoch 0042/0050 | Loss: 1.85855 | Accuracy: 0.35800 | \n",
      "Epoch 0043/0050 | Loss: 1.85395 | Accuracy: 0.35700 | \n",
      "Epoch 0044/0050 | Loss: 1.84980 | Accuracy: 0.36000 | \n",
      "Epoch 0045/0050 | Loss: 1.84476 | Accuracy: 0.36000 | \n",
      "Epoch 0046/0050 | Loss: 1.83999 | Accuracy: 0.36200 | \n",
      "Epoch 0047/0050 | Loss: 1.83557 | Accuracy: 0.36200 | \n",
      "Epoch 0048/0050 | Loss: 1.83127 | Accuracy: 0.36300 | \n",
      "Epoch 0049/0050 | Loss: 1.82735 | Accuracy: 0.36700 | \n",
      "Epoch 0050/0050 | Loss: 1.82316 | Accuracy: 0.36800 | \n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, lr=0.05, verbose=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is very low. This is because the model implemented above is very simple. It has just 3340 parameters. This is not enough to learn the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 36.80%\n"
     ]
    }
   ],
   "source": [
    "train_acc = model.evaluate(X_train, y_train, metric=\"accuracy\")\n",
    "print(f\"Train Accuracy: {train_acc*100:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the training accuracy is about 37%. Let's see how the model performs on the test data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 34.30%\n"
     ]
    }
   ],
   "source": [
    "test_acc = model.evaluate(X_test, y_test, metric=\"accuracy\")\n",
    "print(f\"Test Accuracy: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, the test accuracy is very close to the training accuracy. This means that the model is not overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
